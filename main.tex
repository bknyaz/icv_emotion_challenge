\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{url}
\title{Emotion challenge fact sheet}
\author{iCV}
\date{February 2017}

\begin{document}

\maketitle

\section{Team details}

\begin{itemize}
\item Team name: bknyaz                                  
\item Team leader name: Boris Knyazev                           
\item Team leader address, phone number and email: 

Moscow, Russia

\texttt{8e8all@gmail.com}, \texttt{borknyaz@gmail.com}

\item Rest of the team members: None                    
\item Team website URL (if any): \url{https://github.com/bknyaz}
\item Affiliation: NTechLab
\end{itemize}

\section{Contribution details}

\begin{itemize}
\item Title of the contribution: Simple unsupervised learning method
\item Final score: 86.89\%                                              
\item General method description: This result is obtained based on the model described in [1]. The model is a convolutional neural network, filters of which are trained layer-wise using k-means clustering, that is without backpropagation. Recursive autoconvolution is applied to image patches before $k$-means, which improves results. A linear SVM is applied on top of extracted features. In this challenge, a committee of 5 models with a single convolutional layer of 512 filters turned out to work well.
The task of this challenge is treated as a standard image classification problem with 50 image classes.

\item References

[1] B. Knyazev, E. Barth and Thomas Martinetz, "Recursive Autoconvolution for Unsupervised Learning of Convolutional Neural Networks", accepted to IJCNN-2017
\item Representative image / diagram of the method        
\item Describe data preprocessing techniques applied (if any): faces are extracted and aligned using dlib (\url{https://github.com/davisking/dlib}). Images are downsized before face extraction to speed up the process.
\end{itemize}


\section{Face Landmarks Detection}
\subsection{Features / Data representation}
%Describe features used or data representation model FOR FACE LANDMARKS DETECTION (if any)

Face Landmarks are extracted by dlib, they are used to align faces.

\subsection{Dimensionality reduction}
%Dimensionality reduction technique applied FOR FACE LANDMARKS DETECTION (if any)

\subsection{Compositional model}
%Compositional model used, i.e. pictorial structure FOR FACE LANDMARKS DETECTION (if any)

\subsection{Learning strategy}
%Learning strategy applied FOR FACE LANDMARKS DETECTION (if any)

Publicly available Face Landmarks model is used: available at \url{http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2}.

\subsection{Other techniques}
%Other technique/strategy used not included in previous items FOR FACE LANDMARKS DETECTION (if any)

\subsection{Method complexity}
%Method complexity FOR FACE LANDMARKS DETECTION


\section{Dominant emotion recognition}

I treat all 50 emotions as independent (i.e. each image has one of the labels 0-49), so prior knowledge that there are dominant and complementary emotions were not used.
I chose this approach, because: 

1) it's the most straightforward solution;

2) I tried to use prior knowledge and built some combinations of basic emotions and it did not work better in my case.

\subsection{Features / Data representation}
%Describe features used or data representation model FOR DOMINANT EMOTION RECOGNITION (if any)

\subsection{Dimensionality reduction}
%Dimensionality reduction technique applied FOR DOMINANT EMOTION RECOGNITION (if any)

\subsection{Compositional model}
%Compositional model used, i.e. pictorial structure FOR DOMINANT EMOTION RECOGNITION (if any)

\subsection{Learning strategy}
%Learning strategy applied FOR DOMINANT EMOTION RECOGNITION (if any)

\subsection{Other techniques}
%Other technique/strategy used not included in previous items FOR DOMINANT EMOTION RECOGNITION (if any)

\subsection{Method complexity}
%Method complexity FOR DOMINANT EMOTION RECOGNITION


\section{Complementary emotion recognition}
\subsection{Features / Data representation}
%Describe features used or data representation model FOR COMPLEMENTARY EMOTION RECOGNITION (if any)

\subsection{Dimensionality reduction}
%Dimensionality reduction technique applied FOR COMPLEMENTARY EMOTION RECOGNITION (if any)

\subsection{Compositional model}
%Compositional model used, i.e. pictorial structure FOR COMPLEMENTARY EMOTION RECOGNITION (if any)

\subsection{Learning strategy}
%Learning strategy applied FOR COMPLEMENTARY EMOTION RECOGNITION (if any)

\subsection{Other techniques}
%Other technique/strategy used not included in previous items FOR COMPLEMENTARY EMOTION RECOGNITION (if any)

\subsection{Method complexity}
%Method complexity FOR COMPLEMENTARY EMOTION RECOGNITION


\section{Joint dominant and complementary emotion recognition}
\subsection{Features / Data representation}
%Describe features used or data representation model FOR JOINT DOMINANT AND COMPLEMENTARY EMOTION RECOGNITION (if any)
Features are extracted using a single layer convolutional network consisting of a batch-norm layer, convolutional layer with 512 filters, max-pooling, ReLU rectifier, rootsift normalization. The input to the network is a $96\times96\times3$ aligned face image, max-pooling is performed for $16\times16$ non-overlapping regions, so that the feature vector is $6\times6\times512=18432$ dimensional.
Filters are trained with $k$-means and recursive autoconvolution orders 1-3.

\subsection{Dimensionality reduction}
%Dimensionality reduction technique applied FOR JOINT DOMINANT AND COMPLEMENTARY EMOTION RECOGNITION (if any)

\subsection{Compositional model}
%Compositional model used, i.e. pictorial structure FOR JOINT DOMINANT AND COMPLEMENTARY EMOTION RECOGNITION (if any)

\subsection{Learning strategy}
Data augmentation in the form of horizontal flipping is applied both for training and test samples, so that there are two times more images than provided.
A linear SVM is trained on features extracted from samples.
%Learning strategy applied FOR JOINT DOMINANT AND COMPLEMENTARY EMOTION RECOGNITION (if any)

\subsection{Other techniques}
%Other technique/strategy used not included in previous items FOR JOINT DOMINANT AND COMPLEMENTARY EMOTION RECOGNITION (if any)

\subsection{Method complexity}
%Method complexity FOR JOINT DOMINANT AND COMPLEMENTARY EMOTION RECOGNITION


\section{Global Method Description}

\begin{itemize}
\item Total method complexity: \textbf{unknown}
\item Which pre-trained or external methods have been used (for any stage, if any): \textbf{none}
\item Which additional data has been used in addition to the provided training and validation data (at any stage, if any): \textbf{none} 
\item Qualitative advantages of the proposed solution: 

- no external data and no pre-trained models are used, 

- training can be performed relatively fast,

- the model is simple and general purpose, so there are only few parameters that were  tuned for this task to obtain relatively good classification results.

\item Results of the comparison to other approaches (if any): \textbf{none}

\item Novelty degree of the solution and if is has been previously published: the paper describing the model is accepted to IJCNN-2017.
\end{itemize}

\section{Other details}

\begin{itemize}
\item Language and implementation details (including platform, memory, parallelization requirements): 

My testing environment is following:

- Ubuntu 16.04 LTS

- Matlab R2015b

- 32GB RAM

- Xeon CPU E5-2620 v3 @ 2.40GHz

- Optional: CUDA 7.5, cuDNN-v5, NVIDIA GTX 980 Ti

\item Detailed list of prerequisites for compilation

- gcc 5.4.0

- MatConvNet

- VLFeat

- Liblinear

\item Human effort required for implementation, training and validation?: 

1 person and about 6 hours

\item Training/testing expended time? 

3 hours face extraction, 1 hour model training

\item General comments and impressions of the challenge?
\end{itemize}
\end{document}
